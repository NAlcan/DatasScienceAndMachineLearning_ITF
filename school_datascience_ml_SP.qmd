---
title: "2nd School DDSS and ML"
format: html
date: "`r Sys.Date()`"
---

* Dropbox folder with materials: bit.ly/ai2-dsml2023

# Dia 1

### Introduction to Machine Learning. R Cobe

* How to estimate the function f ?
  - The statistical process starts from a set of known events
    + Training set
* Each event has one or more predictor variable values X : X1 , X2 , ..., Xn and an output value Y
* Evaluation of function f performance
* Distance between the predicted value and the observed value ε
* Use statistical learning on the training set to estimate function f ;
  - Find a function $\hat{f}$ such that Y ≈ $\hat{f}(X)$ for any observation $(X , Y)$
  
  
* Si pensamos en una regresion lineal $f(x) = ax +b$
 - $f(x)$ y $x$ estàn dados, porque fueron obtenidos en el proceso que genero los datos. a y b son parametros a estimar por el modelo
  - $ax +b$ representa el espacio de la "hipotesis" sobre la que vamos a buscar los parametros que tengan una buen a performance en set de entrenamiento.
  - Diremos que la hipotesis "generaliza" bien si predice adecuadamente nuevos casos $y$
  - Estamos buscando aprender la distribución condicional de $P(y|x)$
  
* Si tenemos dos "hipotesis" consistentes con los datos, ambas representan "bien" los datos, la mas simple es la mejor: **Ockham`s razor**


* Iterative Machine Learning Design
  - Define the problem to be tackled with a predictive model
  - Organize data according to the defined problem
  - Define an evaluation metric
  - Split the data into training and testing according to the metric
  - Inspect the solution
  - Propose improvements to the model or data organization

* ML solo piensa en números. Incluso cuando nosotros le damos una etiqueta o un string al modelo, internamente es convertido a valores numéricos

### Introduction to Artificial Neural Networks


* Lo que constituye la "información" del cerebro no son las neuronas en si, sino como esta organizada su estructura, ya es lo que permite la transferencia de la información

* La natrualeza de las neuronas es recibir un "input" de otras unidades y decidir en base a umbrales si disparar o no una "respuesta"

##### How do they work?

* Control the influence from one neuron on another:
  - Excitatory when weight is positive; or
  - Inhibitory when weight is negative;

* Nucleus is responsible for summing the incoming signals;

* __If the sum is above some threshold, then fire!__

![](img/nnet_structures.png)

##### Function Approximation Machines

* Datasets as composite functions: $y = f^{∗}(x)$
* Maps x input to a category (or a value) y;
* Learn synapses weights and approximate y with $\hat{y}$:
* $\hat{y} = f (x; w)$
* Learn the w parameters (Los weights son los parametros a estimar)

* Tenemos:
  - _Input, Output and Hidden layers_
  - _Hidden_ as "not defined by the output"
  
Los w se obtienen computacionalmente

El erro no se puede evaluar unicamente como $y - \hat{y}$ porque podemos obtener tanto valores negativos como positivos, dificil de cuantificar la magnitud LIDS-UNICAMP/FLIM-Builderdel error. Por eso se transforman en errores cuadráticos mediante: $(y - \hat{y})^2$
El problema de esta métrica es que puede variar la escala si transformamos los datos o no. Por lo que por is sola no dice mucho. Es útil para comparar modelos pero no para presentar los resultados

Para una Nnet la ecuación $\hat{y} = W \times x$ comparte un intercepto unico y el modelo solo puede estimar la pendiente. 

$\hat{y} = Wx + b$ le agrega un intercepto, que en Nnet se llama el sesgo (bias)

Input -> weight -> bias -> output


#### How to detect the correct weights

* Gradient descent:

Finding the minimum of a function;
  - Look for the best weights values, minimizing the error;
  - Takes steps proportional to the negative of the gradient of the function at the current point.mong several activation functions, the Rectified Linear Unit
(ReLU) is the most popula
  - Gradient is a vector that is tangent of a function and points in the direction of greatest increase of this function

* "Gradient" (partial derivative for every input variable of function) es una función matematica que recorre el espacio, cambiando de uno los valores y viendo como impacta el resultado en el error

* "cost" es equivalente a error function: $j(w)$

* El gradeint es una linea tangecial a la estimacion del erro. Errores alto dan lineas con pendientes grandes, a me dida que el error decrece hacia un minimo (hiperbola negativa) la pendiente de esta recta tangencial tiende a cero (recta horizontal)

#### Perceptron 

* Primer modelo de redes Neuronales. Basado en los trabajos de McCulloch and Pitts.

* El objetivo es encontrar un hiperplano ("decisión boundary") donde los datos sean completamente separables. Basado en los pesos estimados, un valor umbral y el coeficiente $\alpha$ que indica cuanta importancia le damos a cada paso dinde se actualizan los pesos. 

* Esto nos conduce a que con un mismo algoritmo y set de datos en distintas instancias podemos obtener distintos hiperplanos donde en todos los casos los datos son linealmente separables. Como no conocemos ese hiperplano y en contexto ML solo nos importa las predicciones no importa.

* How does its algorithm work? Let’s see:
1. Assign random weights to w.
2. Initialize $\alpha$.
3. $t = 0$.
4. For each sample $x_{i} \in X^1$ , do:
  $w^(t+1) = w^(t) + \alpha(yi − h_{w^{(t)}} (x_{i} ))x_{i}$
5. Repeat step 4 until some convergence criterion is established.


Cuando los datos no son linealmente separables, las cosas se empiezan a complicar. Se logra modficando las _funciones de activación_ a otras que permitan construir "regiones" de separación no lineales

* Perceptron es una forma de resmong several activation functions, the Rectified Linear Unit
(ReLU) is the most populaolverlo, como una combinación de diferentes layers. Ej una linear y otra no linear

### Multilayer Perceptron

* Grupo de neuronas que combinadas, permiten un mayor número de funciones de decisión

# Dia 2
## Convolutional neural networks (CNN). A. Falcao
CNN parte central del deep laerning

* Pasos: deteccion, segementacion, explainable encoders

* CNN are neural networks composed by and _encoder_ for feature extraction and a _predictor_ for classification/regresion

* The predictor may use the activation map from multiple convolutional blocks (usualmente el caso de segmentacion)

#### basic definitions and image processing operations

* Multichannel image: Canales en los que se puede descomponer una imagen; El numero de convolutional filters que se usen, se transforma en el numero de canales. Un imagen 3D en escala de gris de un tomografo, es en un canal. pero si luego aplicamos 10 filtros, se transforma en una imagen de 10 canales
$m$ es el número de canales. Una imagen visible en RGB, m=3. 
Para m=3 canales, cada pixel p es representado por un punto $I(p) = (I1(p), I2(p), I3(p)) \in R^{3}$

* Adjacency relation (A); es una relacion binaria que considera la disntancia entre pixels; CNNs adoptan una relacion _rectangular_ en 2D.
Es decir mira el pixl del centro y todos los adjacentes que formen un rectagulo alrededor del

* Image patch; La concatenacion de los atributos I(q1)*I(q2)*...*I(qn) de los pixeles adyacentes de p, que definene un Image Patch; Una imagen con 3 canales y 9 vecinos tiene un patch que es un vector de 27 elementos;

* kernel; es un vector de pesos del mismo tamano que los images patches; A kernel bank es un set de kernels;

*  The convolution between an input image (activation map), with m channels, and a kernel bank with b kernels, with m channels each, outputs an activation map with b channels.
__Zero-padding__ is usually adopted when defining X(p). Kernel and patch must have the same shape before their vectorization. This example shows the case the input image and kernel have single channels;
Es un parametro que permite mantener la dimension de la imagen orifinal luego de aplicar el kernel patch

* Activation; mong several activation functions, the Rectified Linear Unit (ReLU) is the most popular

* Em una convolution, cada pixel un perceptron con los mismos weights

* Pooling; agregar la informacion en la mismbit.lya locacion; Es una frma de dowsample la informacion de la imagen. Por ejemplo, consiederando un pixel si y uno no, tanto en la vertical como en la horizontal.

* Normalizations may be applied to any image with channels or, in batch, to a set m-channel images before/after any step in a convolutional layer.
They are important to avoid discrepancies among local activations along the network. They create a new image with m channels or a new set m-channel images.
_Batch normalization_ is very useful to standardize local activations and eliminate the need of bias learning.

* Si convolucionamos una imagen con un set de filtros. los filtros se encargan de extraer los distintos patrones de la imagen. Cada filtro va a llevar una funcion de activacion

* __Flattening__ is the vectorization of each channel $B_{k} , k = 1, 2,... , b$, of an activation map followed by their concatenation ( usado en contexto de clasificación)

### CNNs for image identification and segmentation

* CNNs for identification and segmentation mainly differ in the predictor
 - For identificExplainableation, they use flattening followed by a pattern classifier, usually a multi-layer perceptron (MLP) due to the training by backpropagation. However, it could be a support vector machine (SVM)

* For segmentation, they may use transposed and normal convolutions, batch normalization, activations, skip connections, and post-processing. FPC1PC2Marginal topic distribution2%5%10%12345678910Interamous examples are the U-shaped architectures

### Explainable encoders for identification and segmentation

# Dia 3

## Generative models (L.Oliveira)

#### Generative models at glance
* Ejemplos
  - Google duplex: natural chatting with humans (conducting natural conversations, fully autonomous, synchronization with the interlocutors). Chat que conversa con humanos. el mayor desafio es que el algoritmo respete las pausas de la conversacion y los silencios (synchronization)
  - Voice cloning (transalate conversations using the original voice)
  - Automatic staning (tincion automatica de imagenes de tejido biologicos para mejorar diagnosticos)
  - Leonardo.ai (https://leonardo.ai/; image generator from text)
* Generative models: ML models that learn to generate new data samples, similar to the training data
* Challeenges for generative models : Complex data (requires very large models to capture all nuances of the features and distributions) and complex models (powerfull processing, difficulty to assess performance, complex control to generate data diversity)

#### mathematics foundations of generative models
* Probability and ML
  - En el contexto de ML tenemos que pensar en features ( $X = {x1, x2, ..., xn}$) y labels ( $Y=y$); $P(Y,X) = P(y. x1,x1,...xn)$
- En regresion y calsificacion clasicos nos interesa saber el valor de Y dado un set de features de x. 
- En genrative models, nos interesa conocer las features dado que la label es Y=y
- Libro: "o andar de bebado". sobrePC1PC2Marginal topic distribution2%5%10%12345678910Inter probabilidad
- Teorema Bayes: $posterior = \frac{prior \times likelihood}{evidence}$
- Discriminative models: P(label|features) 
  - Logistic regression
  - SVM
  - Redes Neuronales
  - Random forest
  + Se centran en buscar el hiperplano de separacion de los datos clasificacos como ]diferentes
- **Generative models**: Rewrite Bayes: $P(X|Y=y) = P(X,Y)/p(y)$
  + Se usa p(x,Y) to _sample_ new data
- __Latent variables__ concepto claves. variables que no pueden ser registradas directamente sobe el objeto de estudio, pero se pueden inferir a partir de las features medidas

#### Warming up with LDA
* LDA: Latent Dirichlet Allocation. Model for topic modelling; El topico (cluster de informacion identica "palabras" compartida en una serie de documentos). El topico en este caso es latente, porque no sabemos como se van agrupar,en que docuemnto estan ni con que frecuencia;
* Bayesian network based en Dirichlet distributon
  - Observabl variables: words
  - latent variables: topics
* Goals:
  - Discovering topics in a corpus of word
  - the proportion of this topics in each document
* Assuming that:
  - each document is a mixture of latent topics
  - each topic is a distribution over words
* Pre-processing of your data is very importante
  - Tokenization
  - Lemmatizacion (verbs in third person changes to first peerson, past and future to present)
  - Stemming: words are reduced to their root form

### Deep generative Models
* "deep" referie al numero de layers (mas especificamente las hidden layers). In 90's las redes tenian una o maximo dos hidden layers. 

#### Boltzmann machine
* Established the concepts of stastistical physiscs ( no son generative models pero son la base sobre lo que se van a basar modelos generativos)
* They are probabilistic, unsupervised models based on energy
* Low energy -> High probability / High energy -> Low probability
* El objetivo es minimizar la energy function

#### Restricted Boltzmann machine (RBM)
* Es restricta por reduce el numero de conexiones entre los hidden and visible (inputs) nodes. No tiene outputs
* __Total Energy:__ No es estrictamente un porbabilidad, es una function. You can use this functionfr representing how will the nodes will be connected. Esta funcion se puede transformar en una funcion de probabilidad que depende de los mismos parametros que la total energy

#### Deep Belief Network
* Es un stack de RBMs. El output de una RMB es utilizado como input para otra RBM
* es posible agregar todas las RBM que se quieran con algunos riesgos;
  + Vanishing gradient
  + Local minima
* Usos: 
  - pre processing
  - Training
  - fine tunning

#### Autoencoders
* Autoencoders sirven para aprender representations
* Se le da de input una muestra de los datos, y de output develve una version similar a los datos
* Se entrenan por backpropagation
* NOT a generative model and NOT supervised
* they are used to learn a representations in a latent feature space (bottleneck)
* Input is an image, output is teh same image with less noise
* El foco esta en aprender la representacion latente (con sus pesos y sus funciones de activacion)

#### Variational Autoencoders (VAE)
* Este si es un modelo generativo. No supervisado. Usa una arcquitectura similar a los Autoencoders
* In the bottleneck, VAE learns a posterior
* La diferencia con los AE es que aca podes controlar la representacion latente, y ṕor ende mejor control sobre el output

#### Generative Adversarial Networks
* Apartir de un training set y un random noise que es pasado por un generador (una NNet) para generar versiones fake, se les alimenta a un disciminador (otra NNet) para detectar fraudes;
* La arquitectura parece analisis supervisado, pero en realidad no lo es porque no tenemos las etiquetas sino que se "generan en el camino"
* Discriminator and Generator are trained separately

### chatGPT
* GPT = Generative Pre-trained Transformer
* La tarea principal la hacen los metodos de Natural Language Processing (NLP)
* [ChatGPT and Turing Test](https://www.nature.com/articles/d41586-023-02361-7)
* [Attention is all you need](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwiTnqPrzvuCAxWOs5UCHXPQBNwQFnoECA4QAQ&url=https%3A%2F%2Fpapers.neurips.cc%2Fpaper%2F7181-attention-is-all-you-need.pdf&usg=AOvVaw1cAtW29vELY8ze9FV79yz3&opi=89978449). Explanin the necesity to use transformers in the context of chatGPT. The paper presents a novel sequence-to-sequence architecture for natural language processing that replaced the traditional recurrent neural networks;
   - [Explaines on Medium](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwiTnqPrzvuCAxWOs5UCHXPQBNwQFnoECCkQAQ&url=https%3A%2F%2Fmedium.com%2F%40zaiinn440%2Fattention-is-all-you-need-the-core-idea-of-the-transformer-bbfa9a749937&usg=AOvVaw0NW2TKZCKBhwHNwhjTPr77&opi=89978449)
* 
